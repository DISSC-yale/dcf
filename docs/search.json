[{"path":"https://DISSC-yale.github.io/dcf/articles/standards.html","id":"naming","dir":"Articles","previous_headings":"","what":"Naming","title":"Standards","text":"general guidelines naming files: use portable characters: Best stick -z0-9_-, certainly never use :. Keep names short: total path length limit Windows, avoid long files names especially deeply nested within directories. Avoid duplicating information path (e.g., instead category/category_data.csv use category/data.csv). Avoid new files: file represents thing (e.g., result download given source), keep name, opposed dates version numbers appended name. New versions files overwrite previous versions, potentially merged, deepening data source. Versions files retained git tree, rather separate files. similar considerations naming variables: Best stick limited set characters (-z0-9_). Keep lengths minimal, still identifiable – able tell variable means name, complete information stored measure info entry. instance, include subset value-related information multiple variants (e.g., value_count value_percent). Make names unique across source projects. means including enough relevant source information. source may implicitly include information value, kept name, made explicit measure info.","code":""},{"path":"https://DISSC-yale.github.io/dcf/articles/standards.html","id":"compression","dir":"Articles","previous_headings":"","what":"Compression","title":"Standards","text":"Almost data files can compressed compressed. main reason compress file meant viewing, rather read . Gzip portable type compression, files gzip-compressed can read URL, rather needing downloaded read separately. makes gzip good standard output files. LZMA (xz) generally results smaller files, may best raw files. Parquet files default snappy compression, can also use gzip. Gzip generally results smaller files, slightly less readily usable browsers, may best use snappy files meant web, use gzip otherwise. vroom package, among others, automatically compresses writing, decompresses reading, based file name: standard functions (like read.csv) now automatically decompress, automatically compress, connection must used writing: function doesn’t automatically handle compression extensions, accept connection, can use gzfile function across compression types read:","code":"data <- vroom::vroom(\"data.csv.xz\") vroom::vroom_write(data, \"data.csv.xz\", \",\") data <- read.csv(\"data.csv.xz\") write.csv(data, xzfile(\"data.csv.xz\"), row.names = FALSE) data <- arrow::read_csv_arrow(gzfile(\"data.csv.xz\"))"},{"path":"https://DISSC-yale.github.io/dcf/articles/standards.html","id":"scripts","dir":"Articles","previous_headings":"","what":"Scripts","title":"Standards","text":"automated scripts must run within fresh remote machine. Packages used within script available, depending project’s renv.lock file date (potentially updated dcf_update_lock). absolute file paths, relative local paths outside project used. Scripts run separately environment, information passed . need pass information scripts, write file scripts can access (within project).","code":""},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/articles/standards.html","id":"within-scripts","dir":"Articles","previous_headings":"Scripts > Regulating Runs","what":"Within Scripts","title":"Standards","text":"Within scripts, might want make complete re-running depend state original data (e.g., date data last update). state available depend source, state value, can store project’s file refer runs. general state hash raw files, ingest.R file might look like : state value isn’t ideal since need re-download files calculate . Better use form state ID provided source (file hash update data).","code":"# calcualte the raw state raw_state <- as.list(tools::md5sum(list.files(   \"raw\",   recursive = TRUE,   full.names = TRUE )))  # read the project's process file process <- dcf::dcf_process_record()  # process raw only if state has changed if (!identical(process$raw_state, raw_state)) {    # some code to read raw files and write standard files      # write the new raw state to the project's process file   process$raw_state <- raw_state   dcf::dcf_process_record(updated = process) }"},{"path":"https://DISSC-yale.github.io/dcf/articles/standards.html","id":"within-source-projects","dir":"Articles","previous_headings":"Scripts > Regulating Runs","what":"Within Source Projects","title":"Standards","text":"source projects, process.json 2 fields can used control script run: manual true, script skipped run dcf_built – run dcf_process. may useful script depend local resources manual process, want run locally. frequency 0, script run every frequency days. may useful build process run frequently, know particular script need run less frequently (e.g., data source updates year).","code":""},{"path":"https://DISSC-yale.github.io/dcf/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Yale Data-Intensive Social Science Center. Funder, copyright holder. Micah Iserman. Maintainer, author.","code":""},{"path":"https://DISSC-yale.github.io/dcf/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Iserman M (2026). dcf: dcf: Data Collection Framework. R package version 0.1.0, https://DISSC-yale.github.io/dcf.","code":"@Manual{,   title = {dcf: dcf: Data Collection Framework},   author = {Micah Iserman},   year = {2026},   note = {R package version 0.1.0},   url = {https://DISSC-yale.github.io/dcf}, }"},{"path":"https://DISSC-yale.github.io/dcf/index.html","id":"data-collection-framework","dir":"","previous_headings":"","what":"dcf: Data Collection Framework","title":"dcf: Data Collection Framework","text":"R package establish work within data collection framework.","code":""},{"path":"https://DISSC-yale.github.io/dcf/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"dcf: Data Collection Framework","text":"","code":"# install.packages(\"remotes\") remotes::install_github(\"dissc-yale/dcf\")"},{"path":[]},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/index.html","id":"full-projects","dir":"","previous_headings":"Get Started > Projects","what":"Full Projects","title":"dcf: Data Collection Framework","text":"data collection project ultimately consists source bundle projects: Start initializing overall project: add source project, ingest data single source, produce standardized data file: add bundle project, use standardized source files produce data product:","code":"- collection_project   - data     - source_a     - bundle_a dcf_init(\"collection_project\") dcf_add_source(\"source_a\", \"collection_project\") dcf_add_bundle(\"bundle_a\", \"collection_project\")"},{"path":"https://DISSC-yale.github.io/dcf/index.html","id":"standalone-projects","dir":"","previous_headings":"Get Started > Projects","what":"Standalone projects","title":"dcf: Data Collection Framework","text":"source bundle projects can also exist , outside full project. might useful source project particularly big, takes run, special processes want build outside full project. Standalone bundle projects might useful way make independent /varied outputs single full collection project. dcf_add_source dcf_add_bundle functions can used initialize standalone projects, dcf_build, dcf_process, dcf_check functions work .","code":""},{"path":"https://DISSC-yale.github.io/dcf/index.html","id":"processing","dir":"","previous_headings":"Get Started","what":"Processing","title":"dcf: Data Collection Framework","text":"source bundle scripts written, project can built: runs dcf_process dcf_check sub-project, writes report collection_project/report.json.gz, includes processing details (like logs timing) metadata standardized data files.","code":"dcf_build(\"collection_project\")"},{"path":"https://DISSC-yale.github.io/dcf/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 dcf authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf-package.html","id":null,"dir":"Reference","previous_headings":"","what":"dcf: dcf: Data Collection Framework — dcf-package","title":"dcf: dcf: Data Collection Framework — dcf-package","text":"Establishes operates within framework collect data repeatable way.","code":""},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"dcf: dcf: Data Collection Framework — dcf-package","text":"Maintainer: Micah Iserman micah.iserman@gmail.com contributors: Yale Data-Intensive Social Science Center [funder, copyright holder]","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a Bundle Project — dcf_add_bundle","title":"Adds a Bundle Project — dcf_add_bundle","text":"Establishes new data bundle project, used prepare outputs standardized datasets.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a Bundle Project — dcf_add_bundle","text":"","code":"dcf_add_bundle(   name,   project_dir = \".\",   source_files = NULL,   open_after = interactive(),   use_git = TRUE,   use_workflow = FALSE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a Bundle Project — dcf_add_bundle","text":"name Name bundle project_dir Path Data Collection Framework project. source_files list character vector, names paths standard files form source projects (relative project's data directory), distribution file names entries. associates input output files, allowing calculation source state, metadata inheritance source files. open_after Logical; FALSE, open project. use_git Logical; TRUE, initialize git repository. use_workflow Logical; TRUE, add GitHub Actions workflow.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a Bundle Project — dcf_add_bundle","text":"Nothing; creates default files directories.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"project-definition","dir":"Reference","previous_headings":"","what":"Project Definition","title":"Adds a Bundle Project — dcf_add_bundle","text":"process.json file defines project initial attributes: type Always bundle define bundle project. name Name project. scripts List script definitions. source_files character array paths files     used within scripts, relative overall project's data directory. standard_state State source_files: list     keys file paths, relative overall project root, values     MD5 hash files. dist_state State dist directory: list     keys file paths, relative overall project root, values     MD5 hash files. checked Timestamp project last checked dcf_check. check_results Results last check. scripts entry points script run, one default: path path script, relative project's root. last_run Timestamp last processing. run_time long script took run last, milliseconds. last_status Status last run; list entries     success (logical) log (output script).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"project-files","dir":"Reference","previous_headings":"","what":"Project Files","title":"Adds a Bundle Project — dcf_add_bundle","text":"Within bundle project, two files edits: build.R: primary script, automatically rerun.     read data standard directory source projects,     write dist directory. measure_info.json: list non-ID variable names     data files within dist. inherit standard measure info     found source projects referred source_files.     dist name different, still inherit standard measure info,     source_id entry original measure ID used identify original     measure info.     See dcf_measure_info.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_bundle.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds a Bundle Project — dcf_add_bundle","text":"","code":"project_dir <- paste0(tempdir(), \"/temp_project\") dcf_init(\"temp_project\", dirname(project_dir)) dcf_add_bundle(\"bundle_name\", project_dir) list.files(paste0(project_dir, \"/data/bundle_name\")) #> [1] \"README.md\"         \"build.R\"           \"dist\"              #> [4] \"measure_info.json\" \"process.json\"      \"project.Rproj\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a Source Project — dcf_add_source","title":"Adds a Source Project — dcf_add_source","text":"Establishes new data source project, used collect prepare data new source.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a Source Project — dcf_add_source","text":"","code":"dcf_add_source(   name,   project_dir = \".\",   open_after = interactive(),   use_git = TRUE,   use_workflow = FALSE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a Source Project — dcf_add_source","text":"name Name source. project_dir Path Data Collection Framework project. open_after Logical; FALSE, open project. use_git Logical; TRUE, initialize git repository. use_workflow Logical; TRUE, add GitHub Actions workflow.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a Source Project — dcf_add_source","text":"Nothing; creates default files directories.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"project-definition","dir":"Reference","previous_headings":"","what":"Project Definition","title":"Adds a Source Project — dcf_add_source","text":"process.json file defines project initial attributes: type Always source define source project. name Name project. scripts List script definitions. checked project last checked dcf_check. check_results Results last check. standalone Logical; TRUE source project exist     within broader collection project. standard_state State standard directory: list     names file paths, relative overall project root, values     MD5 hash files. raw_state State raw directory,     set within script. vintages list names names files found standard     directory, values dates (arbitrary format). way provide     date separate files dates (e.g., source     data actually collected), included named file's     datapackage.json. scripts entry points script run, one default: path path script, relative project's root. manual Logical; TRUE, run script     dcf_process (dcf_build). frequency often rerun project, days.     checked last run timestamp processed; way     skip processing, can frequent overall process run. last_run Timestamp last processing. run_time long script took run last, milliseconds. last_status Status last run; list entries     success (logical) log (output script). See script standards examples using within sub-project script.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"project-files-","dir":"Reference","previous_headings":"","what":"Project Files","title":"Adds a Source Project — dcf_add_source","text":"Within source project, two files edits: ingest.R: primary script, automatically rerun.     store raw data resources raw/ possible,     use raw/ produce standard-format files standard/.     file sourced location processing, system paths     must relative . measure_info.json: can record information     variables included standardized data files.     See dcf_measure_info.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_add_source.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds a Source Project — dcf_add_source","text":"","code":"project_dir <- paste0(tempdir(), \"/temp_project\") dcf_init(\"temp_project\", dirname(project_dir)) dcf_add_source(\"source_name\", project_dir) list.files(paste0(project_dir, \"/data/source_name\")) #> [1] \"README.md\"         \"ingest.R\"          \"measure_info.json\" #> [4] \"process.json\"      \"project.Rproj\"     \"raw\"               #> [7] \"standard\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_build.html","id":null,"dir":"Reference","previous_headings":"","what":"Run a Project's Build Process — dcf_build","title":"Run a Project's Build Process — dcf_build","text":"Build Data Collection Framework project, involves processing checking data projects.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_build.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run a Project's Build Process — dcf_build","text":"","code":"dcf_build(   project_dir = \".\",   is_auto = TRUE,   ...,   make_diagram = TRUE,   make_file_log = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_build.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run a Project's Build Process — dcf_build","text":"project_dir Path Data Collection Framework project built. is_auto Logical; FALSE, run dcf_process run manually. ... Passes arguments dcf_process. make_diagram Logical; FALSE, make status.md diagram. make_file_log Logical; FALSE, make file_log.json output.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_build.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run a Project's Build Process — dcf_build","text":"version project report, also written project_dir/docs/report.json.gz.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_build.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run a Project's Build Process — dcf_build","text":"","code":"project_file <- \"../../../pophive/pophive_demo\" if (file.exists(project_file)) {   report <- dcf_build(project_file) } #> ⠙ processing source NREVSS (../../../pophive/pophive_demo/data/NREVSS/ingest.R) #>  #> ⠙ processing source NREVSS (../../../pophive/pophive_demo/data/NREVSS/ingest.R)  #> ── downloading resource <https://data.cdc.gov/resource/3cxc-4k8q> ────────────── #> ⠙ processing source NREVSS (../../../pophive/pophive_demo/data/NREVSS/ingest.R)  #> ℹ metadata: <https://data.cdc.gov/api/views/3cxc-4k8q> #> ✔ metadata: <https://data.cdc.gov/api/views/3cxc-4k8q> [526ms] #>  #> ⠙ processing source NREVSS (../../../pophive/pophive_demo/data/NREVSS/ingest.R)  #> ✔ processing source NREVSS (../../../pophive/pophive_demo/data/NREVSS/ingest.R)… #>  #> ⠙ processing source epic #> no staging files found #> ⠙ processing source epic  #> ✔ processing source epic [19ms] #>  #> ⠙ processing source gtrends (../../../pophive/pophive_demo/data/gtrends/ingest.… #> ✔ processing source gtrends (../../../pophive/pophive_demo/data/gtrends/ingest.… #>  #> ⠙ processing source wastewater (../../../pophive/pophive_demo/data/wastewater/i… #> ✔ processing source wastewater (../../../pophive/pophive_demo/data/wastewater/i… #>  #> ⠙ processing source wisqars (../../../pophive/pophive_demo/data/wisqars/ingest.… #> ℹ requesting report <https://wisqars.cdc.gov/reports/?o=MORT&i=8&m=20810&s=0&r=0&ry=2&y1=2018&y2=2018&a=ALL&g1=0&g2=199&a1=0&a2=199&r1=MECH&r2=AGEGP&r3=STATE&r4=YEAR&r5=NONE&r6=NONE&g=00&e=0&yp=65&me=0&t=0> #> ⠙ processing source wisqars (../../../pophive/pophive_demo/data/wisqars/ingest.…  #> ℹ requesting report <https://wisqars.cdc.gov/reports/?o=MORT&i=1&m=20810&s=0&r=0&ry=2&y1=2018&y2=2018&a=ALL&g1=0&g2=199&a1=0&a2=199&r1=MECH&r2=AGEGP&r3=STATE&r4=YEAR&r5=NONE&r6=NONE&g=00&e=0&yp=65&me=0&t=0> #> ⠙ processing source wisqars (../../../pophive/pophive_demo/data/wisqars/ingest.…  #> ✔ processing source wisqars (../../../pophive/pophive_demo/data/wisqars/ingest.… #>  #> ⠙ processing bundle bundle_respiratory (../../../pophive/pophive_demo/data/bund… #> ✔ processing bundle bundle_respiratory (../../../pophive/pophive_demo/data/bund… #>  #>  #> Checking project NREVSS #> ⠙ checking file ../../../pophive/pophive_demo/data/NREVSS/standard/data.csv.gz #> ✔ checking file ../../../pophive/pophive_demo/data/NREVSS/standard/data.csv.gz … #>  #>  #> Checking project bundle_respiratory #> ⠙ checking file ../../../pophive/pophive_demo/data/bundle_respiratory/dist/data… #> ✖ checking file ../../../pophive/pophive_demo/data/bundle_respiratory/dist/data… #>  #>   geography column contains NAs #>  #> Checking project epic #> ⠙ checking file ../../../pophive/pophive_demo/data/epic/standard/children.csv.gz #> ✔ checking file ../../../pophive/pophive_demo/data/epic/standard/children.csv.g… #>  #> ⠙ checking file ../../../pophive/pophive_demo/data/epic/standard/county_no_time… #> ✔ checking file ../../../pophive/pophive_demo/data/epic/standard/county_no_time… #>  #> ⠙ checking file ../../../pophive/pophive_demo/data/epic/standard/no_geo.csv.gz #> ✔ checking file ../../../pophive/pophive_demo/data/epic/standard/no_geo.csv.gz … #>  #> ⠙ checking file ../../../pophive/pophive_demo/data/epic/standard/state_no_time.… #> ✔ checking file ../../../pophive/pophive_demo/data/epic/standard/state_no_time.… #>  #> ⠙ checking file ../../../pophive/pophive_demo/data/epic/standard/weekly.csv.gz #> ✔ checking file ../../../pophive/pophive_demo/data/epic/standard/weekly.csv.gz … #>  #>  #> Checking project gtrends #> ⠙ checking file ../../../pophive/pophive_demo/data/gtrends/standard/data.csv.gz #> ✖ checking file ../../../pophive/pophive_demo/data/gtrends/standard/data.csv.gz… #>  #>   geography column contains NAs #>  #> Checking project wastewater #> ⠙ checking file ../../../pophive/pophive_demo/data/wastewater/standard/data.csv… #> ✔ checking file ../../../pophive/pophive_demo/data/wastewater/standard/data.csv… #>  #>  #> Checking project wisqars #> ⠙ checking file ../../../pophive/pophive_demo/data/wisqars/standard/data.csv.gz #> ✔ checking file ../../../pophive/pophive_demo/data/wisqars/standard/data.csv.gz… #>"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Data Projects — dcf_check","title":"Check Data Projects — dcf_check","text":"Check data files measure info subprojects.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Data Projects — dcf_check","text":"","code":"dcf_check(names = NULL, project_dir = \".\", verbose = TRUE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Data Projects — dcf_check","text":"names Name names projects. project_dir Path Data Collection Framework project. verbose Logical; FALSE, print status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Data Projects — dcf_check","text":"list entry source, containing character vector   including issue codes: not_compressed: file appear compressed. cant_read: Failed read file . geography_nas: file's geography column contains NAs. time_nas: file's time column contains NAs. missing_info: {column_name}: file's indicated column     matching entry measure_info.json.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Data Projects — dcf_check","text":"","code":"if (FALSE) { # \\dontrun{   dcf_check(\"gtrends\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Data Sources — dcf_check_sources","title":"Check Data Sources — dcf_check_sources","text":"Check data files measure info source projects.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Data Sources — dcf_check_sources","text":"","code":"dcf_check_sources(names = NULL, project_dir = \".\", verbose = TRUE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Data Sources — dcf_check_sources","text":"names Name names source projects. project_dir Path Data Collection Framework project. verbose Logical; FALSE, print status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Data Sources — dcf_check_sources","text":"list entry source, containing character vector   including issue codes: not_compressed: file appear compressed. cant_read: Failed read file . geography_missing: File contain geography column. geography_nas: file's geography column contains NAs. time_missing: File contain time column. time_nas: file's time column contains NAs. missing_info: {column_name}: file's indicated column     matching entry measure_info.json.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_check_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Data Sources — dcf_check_sources","text":"","code":"if (FALSE) { # \\dontrun{   dcf_check_sources(\"gtrends\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"Add information variables dataset datapackage.json metadata file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"","code":"dcf_datapackage_add(   filename,   meta = list(),   packagename = \"datapackage.json\",   dir = \".\",   write = TRUE,   refresh = TRUE,   sha = \"512\",   pretty = FALSE,   summarize_ids = FALSE,   open_after = FALSE,   verbose = interactive() )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"filename character vector paths plain-text tabular data files, relative dir. meta Information data file. list list entry entry filename; see details. single list provided multiple data files, apply . packagename Package add metadata ; path .json file relative dir, list read-version. dir Directory look filename, write packagename. write Logical; FALSE, returns paths metadata without reading rewriting packagename. refresh Logical; FALSE, retain existing dataset information. sha number specifying Secure Hash Algorithm function, openssl available (checked Sys.('openssl')). pretty Logical; TRUE, pretty-print datapackage. summarize_ids Logical; TRUE, include ID columns schema field summaries. open_after Logical; TRUE, opens written datapackage saving. verbose Logical; FALSE, show status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"invisible version updated datapackage, also written datapackage.json write = TRUE.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"meta list unnamed entries entry filename, entry can include named entry : source list list lists entries least name, ideally url. ids list list lists entries least variable (name variable dataset).   Might also include map list path JSON file resulting list   entry ID, additional information entity, read features.   files loaded help aggregation, local files included datapackage,   whereas hosted files loaded client-side. time string giving name variable dataset representing repeated observation entity. variables list named entries providing information variables dataset.   See dcf_measure_info. vintage string specifying time /location data produced.","code":""},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_add.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds documentation of a dataset to a datapackage — dcf_datapackage_add","text":"","code":"if (FALSE) { # \\dontrun{ # write example data write.csv(mtcars, \"mtcars.csv\")  # add it to an existing datapackage.json file in the current working directory dcf_datapackage_add(\"mtcars.csv\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_init.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a datapackage.json template — dcf_datapackage_init","title":"Create a datapackage.json template — dcf_datapackage_init","text":"Initialize dataset documentation datapackage.json template, based Data Package standard.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_init.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a datapackage.json template — dcf_datapackage_init","text":"","code":"dcf_datapackage_init(   name,   title = name,   dir = \".\",   ...,   write = TRUE,   overwrite = FALSE,   quiet = !interactive() )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_init.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a datapackage.json template — dcf_datapackage_init","text":"name unique name dataset; allowed characters [-z._/-]. title display name dataset; specified, formatted version name. dir Directory save datapackage.json file. ... passes arguments dcf_datapackage_add. write Logical; FALSE, package object written file. overwrite Logical; TRUE write TRUE, existing datapackage.json file overwritten. quiet Logical; TRUE, print messages navigate files.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_init.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a datapackage.json template — dcf_datapackage_init","text":"invisible list content written datapackage.json file.","code":""},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_datapackage_init.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a datapackage.json template — dcf_datapackage_init","text":"","code":"if (FALSE) { # \\dontrun{ # make a template datapackage.json file in the current working directory dcf_datapackage_init(\"mtcars\", \"Motor Trend Car Road Tests\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Data from the CDC — dcf_download_cdc","title":"Download Data from the CDC — dcf_download_cdc","text":"Download data metadata Centers Disease Control Prevention (CDC).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Data from the CDC — dcf_download_cdc","text":"","code":"dcf_download_cdc(   id,   out_dir = \"raw\",   state = NULL,   parquet = FALSE,   verbose = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Data from the CDC — dcf_download_cdc","text":"id ID resource (e.g., ijqb-a7ye). out_dir Directory save metadata data files. state state ID previous download; provided, download new state match. parquet Logical; TRUE, convert downloaded CSV file Parquet. verbose Logical; FALSE, display status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Data from the CDC — dcf_download_cdc","text":"state ID downloaded files; downloads files (<id>.json <id>.csv.xz) out_dir","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":"data-cdc-gov-urls","dir":"Reference","previous_headings":"","what":"data.cdc.gov URLs","title":"Download Data from the CDC — dcf_download_cdc","text":"resource ID, 3 relevant CDC URLs: resource/<id>: redirects resource's main page,     displayed metadata data preview     (e.g., data.cdc.gov/resource/ijqb-a7ye). api/views/<id>: direct link underlying     JSON metadata (e.g., data.cdc.gov/api/views/ijqb-a7ye). api/views/<id>/rows.csv: direct link full     CSV dataset (e.g., data.cdc.gov/api/views/ijqb-a7ye/rows.csv).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cdc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Data from the CDC — dcf_download_cdc","text":"","code":"if (FALSE) { # \\dontrun{   dcf_download_cdc(\"ijqb-a7ye\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Medicare Disparities Data — dcf_download_cmsmmd","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"Download data Centers Medicare & Medicaid Services (CMS) Mapping Medicare Disparities Population (MMD) tool.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"","code":"dcf_download_cmsmmd(   measure,   population = NULL,   year = NULL,   geography = NULL,   adjust = NULL,   condition = NULL,   sex = c(1:2, \".\"),   age = c(0:4, \".\"),   race = c(1:6, \".\"),   dual_elig = \".\",   medicare_elig = \".\",   refresh_codebook = FALSE,   codebook_only = FALSE,   row_limit = 9999999,   out_file = NULL,   state = NULL,   parquet = FALSE,   verbose = TRUE )  dcf_standardize_cmsmmd(raw_data = NULL)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"measure Name letter code measure download. population population code; either f (Medicare Fee Service) m (Medicare Advantage). year Year(s) download (e.g., 2015:2020). specified, available years included. geography Geography code(s) include, n (national), s (state), c (county). specified, available geographies included. adjust, condition, sex, age, race, dual_elig, medicare_elig One codes indicating variable levels include (see dcf_standardize_cmsmmd). \".\", values across levels, whereas NULL, available levels included (aggregated disaggregated). See Making Requests section. refresh_codebook Logical; TRUE, re-download codebook even exists temporary location (cleared R session). codebook_only Logical; TRUE, return codebook without downloading data. row_limit Maximum number rows return request. API limit appears 100,000. out_file Path CSV Parquet file write data . state codebook state (MD5 hash) recorded previous download; provided, download new state match. parquet Logical; TRUE, convert downloaded CSV file Parquet. verbose Logical; FALSE, display status messages. raw_data raw data downloaded dcf_download_cmsmmd standardized.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"dcf_download_cmsmmd: list: codebook: codebook. codebook_state: MD5 hash codebook. data: downloaded data. dcf_standardize_cmsmmd: raw_data NULL, list entry API parameter, containing named vectors level codes names mapping level values (appear tool's menus). Otherwise, version raw_data coded values converted labels.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":"making-requests","dir":"Reference","previous_headings":"","what":"Making Requests","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"API operates several large files, partitioned measure, year, adjust, dual medicaid eligibility. identified codebook (dcf_download_cmsmmd(codebook_only = TRUE)). files larger API's limit, requests file broken variables within (sex, age, race, condition). best performance, make requests big possible staying 100,000 rows (e.g., setting sex, age, race NULL).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_cmsmmd.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Medicare Disparities Data — dcf_download_cmsmmd","text":"","code":"# find the codes associated with menu values variable_codes <- dcf_standardize_cmsmmd() variable_codes[c(   \"sex\", \"age\", \"race\",   \"adjust\", \"dual_elig\", \"medicare_elig\" )] #> $sex #>        1        2  #>   \"Male\" \"Female\"  #>  #> $age #>       0       1       2       3       4  #>   \"<65\" \"65-74\" \"75-84\"   \"85+\"   \"65+\"  #>  #> $race #>                               1                               2  #>                         \"White\"                         \"Black\"  #>                               3                               4  #>                         \"Other\"        \"Asian/Pacific Islander\"  #>                               5                               6  #>                      \"Hispanic\" \"American Indian/Alaska Native\"  #>  #> $adjust #>                             1                             2  #>           \"Unsmoothed actual\" \"Unsmoothed age standardized\"  #>                             3                             4  #>             \"Smoothed actual\"   \"Smoothed age standardized\"  #>  #> $dual_elig #>               0               1  #> \"Medicare only\"     \"Dual only\"  #>  #> $medicare_elig #>                                             0  #>              \"Old Age / Survivor's Insurance\"  #>                                             1  #>               \"Disability Insurance Benefits\"  #>                                             2  #>                     \"End-Stage Renal Disease\"  #>                                             3  #> \"Both Disability and End-Stage Renal Disease\"  #>   # look at the codebook which defines source files codebook <- dcf_download_cmsmmd(codebook_only = TRUE) #> ℹ retrieving codebook #> ✔ retrieving codebook [107ms] #>  codebook #> # A tibble: 1,537 × 13 #>    File    File.Name Number.of.observations population measure description  year #>    <chr>   <chr>                      <dbl> <chr>      <chr>   <chr>       <dbl> #>  1 \"\"      Mdcr_pmt…                7497844 f          b       medicare r…     2 #>  2 \"dual … Dschrg_F…                9424772 f          d       discharge …     2 #>  3 \"dual … Dschrg_F…                8122052 f          d       discharge …     2 #>  4 \"dual … Dschrg_F…                6318880 f          d       discharge …     2 #>  5 \"\"      Ipdays_F…                7497844 f          i       inpatient …     2 #>  6 \"\"      Mortalit…                3944721 f          m       mortality       2 #>  7 \"dual … Admsn_Fi…                9425012 f          n       admission …     2 #>  8 \"dual … Admsn_Fi…                8122188 f          n       admission …     2 #>  9 \"dual … Admsn_Fi…                6319016 f          n       admission …     2 #> 10 \"year … Principa…               11686440 f          p       principal …     2 #> # ℹ 1,527 more rows #> # ℹ 6 more variables: elig <chr>, race_code <chr>, sex_code <chr>, #> #   adjust <chr>, dual <chr>, url <chr>  if (FALSE) { # \\dontrun{   # download data   downloaded <- dcf_download_cmsmmd(     \"preventive care\",     population = \"f\",     race = \".\",     sex = \".\",     age = NULL,     condition = c(83, 85, 86, 88, 89, 95, 101, 102, 104, 105:107),     adjust = 1   )    # convert codes to levels   data_standard <- dcf_standardize_cmsmmd(downloaded$data) } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_wisqars.html","id":null,"dir":"Reference","previous_headings":"","what":"Download CDC WISQARS Reports — dcf_download_wisqars","title":"Download CDC WISQARS Reports — dcf_download_wisqars","text":"Download reports data CDC's Web-based Injury Statistics Query Reporting System.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_wisqars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download CDC WISQARS Reports — dcf_download_wisqars","text":"","code":"dcf_download_wisqars(   file,   fatal_outcome = TRUE,   brain_injury_only = FALSE,   year_start = 2018,   year_end = year_start,   geography = \"00\",   intent = \"all\",   disposition = \"all\",   mechanism = if (fatal_outcome) 20810 else 3000,   group_ages = NULL,   age_min = 0,   age_max = 199,   sex = \"all\",   race = \"all\",   race_reporting = \"single\",   ethnicity = \"all\",   YPLL = 65,   metro = NULL,   group_by = NULL,   include_total = FALSE,   verbose = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_wisqars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download CDC WISQARS Reports — dcf_download_wisqars","text":"file File save report (csv parquet). fatal_outcome Logical; FALSE, return non-fatal results. brain_injury_only Logical; TRUE, return traumatic brain injury results. year_start Earliest year include. year_end Latest year include. geography State region code. intent Intent ID name: disposition Patient disposition given nonfatal: one multiple (0), treated (1; treated released), transfered (2), hospitalized (3), observed (4; observed/left AMA/unknown). mechanism Mechanism code; default 20810 (injury). codes appear URL m parameter submitting filter. group_ages Logical; FALSE, group ages 5-year bins. age_min Youngest age include. age_max Oldest age include. sex Sex groups include: one multiple (0), male (1), female (2), unknown (3).. race Race groups include: one multiple (0), white (1), black (2), aa (3; American Indian Alaska Native), asian (4), pi (5; Hawaiian Native Pacific Islander), (6; one race). levels apply race_reporting single (default) – provide index race_reporting levels. race_reporting group race groups, none (0), bridge (1), single (2), aapi (3). ethnicity ethnic groups include: one multiple (0), non_hispanic (1), hispanic (2), unknown (3). YPLL Age use calculating Years Potential Life Lost. metro Region type filter: TRUE metropolitan / urban, FALSE non-metropolitan / rural. include region types NULL (default). group_by One variables group . uppercased sometimes abbreviated encoded; see r1 r4 URL parameters. include_total Logical; FALSE, include totals. verbose Logical; FALSE, display status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_wisqars.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download CDC WISQARS Reports — dcf_download_wisqars","text":"list containing parameters request. returned data written file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_download_wisqars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download CDC WISQARS Reports — dcf_download_wisqars","text":"","code":"file <- \"../../../wisqars.csv.xz\" if (file.exists(file)) {   dcf_download_wisqars(file, verbose = FALSE)   vroom::vroom(file) } #> Rows: 1 Columns: 21 #> ── Column specification ──────────────────────────────────────────────────────── #> Delimiter: \",\" #> dbl (21): SupressFlag, Population, medCost, workCost, MedCostAAR, workCostAA... #>  #> ℹ Use `spec()` to retrieve the full column specification for this data. #> ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. #> # A tibble: 1 × 21 #>   SupressFlag Population     medCost    workCost MedCostAAR workCostAAR CombCost #>         <dbl>      <dbl>       <dbl>       <dbl>      <dbl>       <dbl>    <dbl> #> 1           0  326838199 3840756047.     2.32e12       10.5       7008.  2.33e12 #> # ℹ 14 more variables: CombCostAAR <dbl>, CombCostRate <dbl>, #> #   MedCostRate <dbl>, workCostRate <dbl>, CombCostAvg <dbl>, #> #   WorkCostAvg <dbl>, MedCostAvg <dbl>, race_yr <dbl>, deaths <dbl>, #> #   ypll <dbl>, CrudeRate <dbl>, CrudeRateypll <dbl>, ageadj <dbl>, #> #   ageadjypll <dbl>"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_get_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve A Data File — dcf_get_file","title":"Retrieve A Data File — dcf_get_file","text":"Load data file source data project, list versions file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_get_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve A Data File — dcf_get_file","text":"","code":"dcf_get_file(path, date = NULL, commit_hash = NULL, versions = FALSE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_get_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve A Data File — dcf_get_file","text":"path Path file. date Date version load; Date, character format YYYY-MM-DD. match nearest version. commit_hash SHA signature committed version; can first 6 characters. Ignored date provided. versions Logical; TRUE, return list available version, rather ","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_get_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve A Data File — dcf_get_file","text":"versions TRUE, data.frame columns   hash, author, date, message commit.   Otherwise, path temporary file, one extracted.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_get_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve A Data File — dcf_get_file","text":"","code":"path <- \"../../../pophive/pophive_demo/data/wastewater/raw/flua.csv.xz\" if (file.exists(path)) {   # list versions   versions <- dcf_get_file(path, versions = TRUE)   print(versions[, c(\"date\", \"hash\")])    # extract a version to a temporary file   temp_path <- dcf_get_file(path, \"2025-05\")   basename(temp_path) } #>                              date                                     hash #> 1  Sat Jan 31 02:56:54 2026 +0000 08497141c4531a07965c39dd6daa74ff9ad37e84 #> 2  Sat Jan 24 02:41:15 2026 +0000 82fbf03d1b4bdc0ac48bdbf31b14e4dce2cc1418 #> 3  Sat Jan 17 02:38:43 2026 +0000 a4d5b3eb34c94e805110a6969b9a962cba1cc031 #> 4  Sat Jan 10 02:39:48 2026 +0000 32df32f0e36162ee07e45f925a5ea842504290ac #> 5   Tue Jan 6 02:43:16 2026 +0000 ba182c16ba090e0eb23d863124401a60f61c94c9 #> 6  Wed Dec 31 02:41:22 2025 +0000 279493b87f75dc3c77a53ce48005ebe42cbc18c2 #> 7  Sat Dec 20 02:37:18 2025 +0000 8b0d409c529d908252e808968b0b095d771b8613 #> 8  Sat Dec 13 02:37:56 2025 +0000 877bf127049b4779360983435d3205482f2b1c11 #> 9   Sat Dec 6 02:37:00 2025 +0000 6c9669d236a9409c9ca4ff3187cbfcdb31927e20 #> 10  Tue Dec 2 02:38:24 2025 +0000 ed20e66e79bc5a7939adc1af1610bc6f31e3dd5a #> 11 Sat Nov 22 02:33:54 2025 +0000 b59fac32e66056e85e41430c91aad060958306a5 #> 12  Sun Nov 2 02:38:05 2025 +0000 c823cb2c44dcb6260ad0a901ba81e0acc801c6f3 #> 13  Sat Nov 1 09:57:43 2025 -0400 04fafdcf31a126e42642e6010a3100aa63edda81 #> 14 Wed Oct 15 02:35:00 2025 +0000 5563a50413876d209604a2c4fbac0fffbd4ba793 #> 15 Tue Oct 14 06:48:38 2025 -0400 076b852d31b5af16235aa56dde508fa73983d479 #> 16 Sat Sep 27 02:31:30 2025 +0000 cb8a41fa3da3ddedbbee4bf6153c208de7de3a01 #> 17 Sat Sep 20 02:31:17 2025 +0000 520394f79a87bf2fa0a4b1ae2213932e728b1570 #> 18 Thu Sep 18 02:33:21 2025 +0000 ac2f7e138d60f8a861a3d584e134a5fdf5ec78c9 #> 19 Wed Sep 17 15:46:06 2025 -0400 8522c4a6e1f0b30661504f0728e2fafceee4ecfb #> 20 Sat Sep 13 02:27:37 2025 +0000 5d9483923815921ecb1ed700df782b695cb994eb #> 21  Sat Sep 6 02:29:33 2025 +0000 65ff8e099fd579e330315b3f7859c406074832eb #> 22 Sat Aug 30 02:31:18 2025 +0000 1bf85727accd512bdc8dd3100dede7295b604943 #> 23 Sat Aug 16 02:36:12 2025 +0000 ccd85b4da78bc580f3fd533c520d6fbf21bc181d #> 24  Sat Aug 9 02:38:46 2025 +0000 2ef24d54247fb01628c6dc1ddccd071613280fd9 #> 25 Sat Jul 26 02:40:50 2025 +0000 81716bd29b0adbb4c45210c6f10317ab796ba1f5 #> 26 Sat Jul 19 02:39:02 2025 +0000 b5c6f34063227d1b6ba7e458f41faac7b754103a #> 27 Fri Jul 18 15:34:47 2025 -0400 3c39f450353d516ee166f5f6686ced81c6d5ff75 #> 28 Fri Jul 18 06:05:49 2025 -0400 39732a153fa02c1a4350a9a998471ae61c7a8627 #> 29 Fri Jul 18 02:44:23 2025 +0000 c381b11f68d0f1a3447e824049659b6cc685d0c8 #> 30 Thu Jul 17 09:46:50 2025 -0400 8b9395792ca23c342cf25af097d86a519918e2e6 #> 31 Tue Jul 15 02:44:40 2025 +0000 78dd0978bc74bed8e26f7fedc13087bddd409404 #> 32 Mon Jul 14 11:10:58 2025 -0400 f397e907659bbc3c8bb2175232c8b3376562839b #> 33 Sat Jul 12 02:42:02 2025 +0000 2ac6330bd528332cd2e3c1e94391a7c4fbde6d32 #> 34 Fri Jul 11 02:46:42 2025 +0000 14629520528fcd24cc0a90c1206458780a7ce08f #> 35 Thu Jul 10 18:10:38 2025 -0400 ab6649b2b88fb7fc51f1a34f18a29dd40b5e6d11 #> 36  Tue Jul 8 02:35:33 2025 +0000 3afe62043b4290a4199d82721ba510b3fe93ba79 #> 37  Wed Jul 2 02:34:23 2025 +0000 440e5a9e4917c83424b6a3fe933715a22d5fb87b #> 38  Tue Jul 1 15:11:58 2025 -0400 1ef46279c9b98850cdff0d5acfeda88e7d8d4c92 #> 39 Mon Jun 30 00:37:54 2025 +0000 eb977e93221277f616a1a46835ac3daa1f0186ae #> 40 Mon Jun 23 00:38:01 2025 +0000 0576de553d7c11836e020501a500431af581654a #> 41 Mon Jun 16 00:48:12 2025 +0000 04fa04500f67f1bdfb2c6cc02bb0bd3c430bf8bd #> 42  Mon Jun 9 00:36:37 2025 +0000 d978116e3b12926798d8f573bc1d3e913d67a547 #> 43  Mon Jun 2 09:32:13 2025 +0000 784558d5a95e20f3950a36770f82a5a0fabebb21 #> 44 Tue May 27 13:56:02 2025 -0400 36914a3d9b47f91eba0b5d8dfddd357a700fd525 #> [1] \"flua-36914a.csv.xz\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":null,"dir":"Reference","previous_headings":"","what":"Initialize a Data Collection Project — dcf_init","title":"Initialize a Data Collection Project — dcf_init","text":"Establishes new data collection framework project.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initialize a Data Collection Project — dcf_init","text":"","code":"dcf_init(   name,   base_dir = \".\",   data_dir = \"data\",   github_account = \"\",   branch = \"main\",   repo_name = name,   use_git = TRUE,   open_after = FALSE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initialize a Data Collection Project — dcf_init","text":"name Name source. Defaults current directory name. base_dir Path parent project directory (name directory created). name specified, treat current directory name, \"..\" base_dir. data_dir Name directory store projects , relative base_dir. github_account Name GitHub account host repository. branch Name repository's branch. repo_name Name repository. use_git Logical; TRUE, initialize git repository. open_after Logical; TRUE, open project new RStudio instance.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Initialize a Data Collection Project — dcf_init","text":"Nothing; creates default files directories.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":"data-collection-project","dir":"Reference","previous_headings":"","what":"Data Collection Project","title":"Initialize a Data Collection Project — dcf_init","text":"data collection project starts settings.json file, specifies source bundle projects live (data subdirectory default). bulk project source bundle projects, created dcf_add_source dcf_add_bundle. sub-projects place, can operated dcf_build, processes sub-project using dcf_process, checks dcf_check, resulting report.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_init.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Initialize a Data Collection Project — dcf_init","text":"","code":"base_dir <- tempdir() dcf_init(\"project_name\", base_dir) list.files(paste0(base_dir, \"/project_name\")) #> [1] \"README.md\"     \"project.Rproj\" \"scripts\"       \"settings.json\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_load_census.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Census Population Data — dcf_load_census","title":"Download Census Population Data — dcf_load_census","text":"Download American Community Survey population data U.S. Census Bureau.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_load_census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Census Population Data — dcf_load_census","text":"","code":"dcf_load_census(   year = 2021,   out_dir = NULL,   state_only = FALSE,   age_groups = \"9\",   overwrite = FALSE,   verbose = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_load_census.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Census Population Data — dcf_load_census","text":"year Data year. out_dir Directory download file . state_only Logical; TRUE, load state data. still download county data. age_groups list mapping lower-level age groups high-level ones (e.g., list(`<10 Years` = c(\"5 years\", \"5 9 years\"))). name standard mapping (\"7\" \"9\"). FALSE, return lowest-level age groups. overwrite Logical; TRUE, re-download overwrite existing data. verbose Logical; FALSE, display status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_load_census.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Census Population Data — dcf_load_census","text":"data.frame including GEOID region_name   states counties, along population, total within   age brackets.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_load_census.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Census Population Data — dcf_load_census","text":"","code":"if (file.exists(\"../../../pophive/census_population_2021.csv.xz\")) {   dcf_load_census(2021, \"../../../pophive\")[1:10, ] } #> ℹ reading in existing file #> ✔ reading in existing file [118ms] #>  #>    GEOID          region_name    Total <10 Years 10-18 Years 18-24 Years #> 1     01              Alabama  4997675    597446      524935      461491 #> 2     02               Alaska   735951    104061       78673       68835 #> 3     04              Arizona  7079203    852827      761608      672761 #> 4     05             Arkansas  3006309    380228      325557      279234 #> 5     06           California 39455353   4784448     4207984     3665851 #> 6     08             Colorado  5723176    671899      590836      523401 #> 7     09          Connecticut  3605330    378662      365829      345702 #> 8     10             Delaware   981892    110715       96930       83629 #> 9     11 District of Columbia   683154     78027       46995       70406 #> 10    12              Florida 21339762   2266695     1994618     1729159 #>    25-34 Years 35-44 Years 45-54 Years 55-64 Years 65+ Years #> 1       647247      615110      633931      673088    844427 #> 2       116525       96664       87719       93286     90188 #> 3       966670      882914      838963      859601   1243859 #> 4       388499      376431      364713      386286    505361 #> 5      5941622     5341049     5043403     4801117   5669879 #> 6       889933      805249      712196      710408    819254 #> 7       445861      439098      488283      521716    620179 #> 8       127878      115773      121235      139357    186375 #> 9       155714      106798       73601       68414     83199 #> 10     2742442     2626930     2735230     2897723   4346965"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a measurement metadata file — dcf_measure_info","title":"Make a measurement metadata file — dcf_measure_info","text":"Make measure_info.json file, add measure entries existing one.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a measurement metadata file — dcf_measure_info","text":"","code":"dcf_measure_info(   path,   ...,   info = list(),   references = list(),   sources = list(),   strict = FALSE,   include_empty = TRUE,   overwrite_entry = FALSE,   render = NULL,   overwrite = FALSE,   write = TRUE,   verbose = TRUE,   open_after = interactive() )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a measurement metadata file — dcf_measure_info","text":"path Path measure_info.json file, existing created. ... Lists containing individual measure items. See Measure Entries section. info list containing measurement information added. references list containing citation entries. See Reference Entries section. sources list containing source entries. See Sources Entries section. strict Logical; TRUE, allow recognized entries values. include_empty Logical; FALSE, omit entries provided. overwrite_entry Logical; TRUE, replace rather add existing entry. render Path save version path , dynamic entries expanded. See Dynamic Entries section. overwrite Logical; TRUE, overwrite rather add existing path. write Logical; FALSE, write build rendered measure info. verbose Logical; FALSE, display status messages. open_after Logical; FALSE, open measure file writing/updating.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a measurement metadata file — dcf_measure_info","text":"invisible list containing measurement metadata (rendered version made).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"measure-entries","dir":"Reference","previous_headings":"","what":"Measure Entries","title":"Make a measurement metadata file — dcf_measure_info","text":"Measure entries named unique variable name entries (strict): id: Unique identifier measure; entry name.     meant correspond column name containing measure data files.     minimal length still unique across files within project.     contain characters -z, 0-9, _. short_name: Shortest possible display name. long_name: Longer display name. category: Arbitrary category measure. short_description: Shortest possible description. long_description: Complete description. Either description can include     TeX-style equations, enclosed escaped square brackets (e.g.,     \"equation \\\\[a_{} = b^\\\\frac{c}{d}\\\\] used.\"; $...$,     \\\\(...\\\\), \\\\begin{math}...\\\\end{math}). final enclosing symbol must     followed space end string. pre-render MathML     katex_mathml. statement: String dynamic references entity features     (e.g., \"measure value = {value}\"). References can include: value: Value currently displaying variable current time. region_name: Alias features.name. features.<entry>: entity feature, coming entity_info.json GeoJSON properties.         entities least name id entries (e.g., \"{features.id}\"). variables.<entry>: variable feature name         id (e.g., \"{variables.name}\"). data.<variable>: value another variable current time (e.g., \"{data.variable_a}\"). measure_type: Type measure's value. Recognized types displayed special way: year integer show entered (usually whole numbers). numeric         types rounded show set number digits. percent shows {value}%. minutes shows {value} minutes. dollar shows ${value}. internet speed shows {value} Mbps. unit: Prefix suffix associated measure's type, % percent,     Mbps rate. time_resolution: Temporal resolution variable, year week. restrictions: license description restrictions may apply measure. sources: list list list containing source information, including entries: id: ID found _sources entry, inherit entries . name: Name source (organization name). url: General URL source (organization's website). location: specific description source (name particular data product). location_url: direct URL resource (page listing data products). citations: vector reference ids (names reference entries; e.g., c(\"ref1\", \"ref3\")). categories: named list categories, measure entries,     default entry giving default category name. See Dynamic Entries section. variants: named list variants, measure entries,     default entry giving default variant name. See Dynamic Entries section.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"bundle-entries","dir":"Reference","previous_headings":"","what":"Bundle Entries","title":"Make a measurement metadata file — dcf_measure_info","text":"Measures bundle projects can inherit information provided source bundles. happen either measure name existing measure (case, info can empty: \"existing_measure\": {}), special source_id entry maps existing measure (\"new_measure\": {\"source_id\": \"existing_measure\"}). bundle files tall format, measures stacked, can documented (1) using special levels entry map levels variable identifies measure, (2) using special measure_column entry variable containing values, point identifier variable: \"measure\": {\"levels\": {\"existing_measure\": {}, \"new_measure\": {\"source_id\": \"existing_measure\"}}} \"value\": {\"measure_column\": \"measure\"}","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"duplicate-names","dir":"Reference","previous_headings":"","what":"Duplicate Names","title":"Make a measurement metadata file — dcf_measure_info","text":"strongly preferable every distinct measure name unique across files within collection project. names must duplicated files, can prefixed path file containing , relative data directory (standalone parent), separated bar (|; e.g., subproject_name/dist/data.csv.gz|measure_name).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"dynamic-entries","dir":"Reference","previous_headings":"","what":"Dynamic Entries","title":"Make a measurement metadata file — dcf_measure_info","text":"may several closely related variables dataset, share sections metadata, formulaic differences. cases like , categories /variants entries can used along dynamic notation construct multiple entries single template. Though functionally , categories might include broken-subsets total (race groups, categories total population), whereas variants may different transformations variable (raw counts versus percentages). dynamic entries, {category} {variant} refers entries categories variants lists. default, replaced name entries lists (e.g., \"variable_{category}\" categories = \"\" become \"variable_a\"). default entry change behavior (e.g., categories = list(= list(default = \"b\") become \"variable_b\"). Adding .name force original behavior (e.g., \"variable_{category.name}\" \"variable_a\"). name \"blank\" treated empty string. notation appears measure info entry, first default matching name categories variants list; example, short_name list(short_name = \"variable {category}\") categories = list(= list(short_name = \"(category )\")) become \"variable (category )\". force behavior, entry name can included notation (e.g., \"{category.short_name}\" \"variable (category )\" entry). string entries processed dynamically – list-like entries (source, citations, layer) appearing categories variants entries fully replace base entry. Dynamic entries can kept dynamic passed data site, can rendered uses, rendered version dynamic entry replaced unique combinations categories variants entries, assuming used dynamic entry's name (e.g., \"variable_{category}_{variant}\"). See Examples.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"reference-entries","dir":"Reference","previous_headings":"","what":"Reference Entries","title":"Make a measurement metadata file — dcf_measure_info","text":"Reference entries can included _references entry, names corresponding included measures' citation entries. can include entries: id: reference id, entry name. author: list list lists specifying one authors. can include     entries given family names. year: Year publication. title: Title publication. journal: Journal publication appears. volume: Volume number journal. page: Page number journal. doi: Digital Object Identifier, link made (https://doi.org/{doi}). version: Version number software. url: Link publication, alternative DOI.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"source-entries","dir":"Reference","previous_headings":"","what":"Source Entries","title":"Make a measurement metadata file — dcf_measure_info","text":"Source entries can included _sources entry, names corresponding included measures' sources entry. can include entries: name: Name source. url: Link source's site. description: description source. notes: list additional notes source. organization: Name higher-level organization source part . organization_url: Link organization's site. category: top-level category classification. subcategory: lower-level category classification.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_measure_info.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a measurement metadata file — dcf_measure_info","text":"","code":"path <- tempfile()  # make an initial file dcf_measure_info(path, \"measure_name\" = list(   id = \"measure_name\",   short_description = \"A measure.\",   statement = \"This entity has {value} measure units.\" ), verbose = FALSE)  # add another measure to that measure_info <- dcf_measure_info(path, \"measure_two\" = list(   id = \"measure_two\",   short_description = \"Another measure.\",   statement = \"This entity has {value} measure units.\" ), verbose = FALSE) names(measure_info) #> [1] \"measure_name\" \"measure_two\"   # add a dynamic measure, and make a rendered version measure_info_rendered <- dcf_measure_info(   path,   \"measure_{category}_{variant.name}\" = list(     id = \"measure_{category}_{variant.name}\",     short_description = \"Another measure ({category}; {variant}).\",     statement = \"This entity has {value} {category} {variant}s.\",     categories = c(\"a\", \"b\"),     variants = list(u1 = list(default = \"U1\"), u2 = list(default = \"U2\"))   ),   render = TRUE, verbose = FALSE ) names(measure_info_rendered) #> [1] \"measure_name\" \"measure_two\"  \"measure_a_u1\" \"measure_b_u1\" \"measure_a_u2\" #> [6] \"measure_b_u2\" measure_info_rendered[[\"measure_a_u1\"]]$statement #> [1] \"This entity has {value} a U1s.\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Data Project Processes — dcf_process","title":"Run Data Project Processes — dcf_process","text":"Operates data source bundle projects, optionally running source ingest scripts, collecting metadata.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Data Project Processes — dcf_process","text":"","code":"dcf_process(   name = NULL,   project_dir = \".\",   ingest = TRUE,   is_auto = FALSE,   force = FALSE,   clear_state = FALSE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Data Project Processes — dcf_process","text":"name Name source project process. default name current working directory. project_dir Path project directory. specified, called source project, assumed two steps back working directory. ingest Logical; FALSE, re-process standardized data without running ingestion scripts. applies source projects. is_auto Logical; TRUE, skip process scripts marked manual. force Logical; TRUE, ignore process frequencies (run scripts even recently run). clear_state Logical; TRUE, clear stored states processing.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Data Project Processes — dcf_process","text":"list processing results: timings: many seconds scripts took run. logs: captured output scripts. entry entry project. `datapackage.json` file also created / update source's `standard` directory.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Data Project Processes — dcf_process","text":"","code":"if (FALSE) { # \\dontrun{   # run from a directory containing a `data` directory containing the source   dcf_process(\"source_name\")    # run without executing the ingestion script   dcf_process(\"source_name\", ingest = FALSE) } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_epic_staging.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Epic Stating Files — dcf_process_epic_staging","title":"Process Epic Stating Files — dcf_process_epic_staging","text":"Process Epic stating files, lightly standardizing moving raw.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_epic_staging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Epic Stating Files — dcf_process_epic_staging","text":"","code":"dcf_process_epic_staging(   staging_dir = \"raw/staging\",   out_dir = \"raw\",   verbose = TRUE,   cleanup = TRUE,   ... )"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_epic_staging.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Epic Stating Files — dcf_process_epic_staging","text":"staging_dir Directory containing staging files. out_dir Directory write new raw files . verbose Logical; FALSE, show status messages. cleanup Logical; FALSE, remove staging files processed. ... Passes additional arguments dcf_read_epic.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_epic_staging.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Epic Stating Files — dcf_process_epic_staging","text":"NULL staging files found.   Otherwise, list entries data metadata.   lists entries recognized standard name,   potentially combined outputs similar dcf_read_epic","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_epic_staging.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Epic Stating Files — dcf_process_epic_staging","text":"","code":"if (FALSE) { # \\dontrun{   # run from a source project   dcf_process_epic_staging() } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":null,"dir":"Reference","previous_headings":"","what":"Interact with a Process File — dcf_process_record","title":"Interact with a Process File — dcf_process_record","text":"Read update current process file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interact with a Process File — dcf_process_record","text":"","code":"dcf_process_record(path = \"process.json\", updated = NULL)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interact with a Process File — dcf_process_record","text":"path Path process JSON file. updated update version process definition. specified, write new process file, rather reading existing file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interact with a Process File — dcf_process_record","text":"process definition source project.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Interact with a Process File — dcf_process_record","text":"See script standards examples using within sub-project script.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_process_record.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interact with a Process File — dcf_process_record","text":"","code":"epic_process_file <- \"../../../pophive/pophive_demo/data/epic/process.json\" if (file.exists(epic_process_file)) {   dcf_process_record(epic_process_file) } #> $name #> [1] \"epic\" #>  #> $type #> [1] \"source\" #>  #> $scripts #> $scripts[[1]] #> $scripts[[1]]$path #> [1] \"ingest.R\" #>  #> $scripts[[1]]$manual #> [1] TRUE #>  #> $scripts[[1]]$frequency #> [1] 0 #>  #> $scripts[[1]]$last_run #> [1] \"2025-11-01 09:31:40\" #>  #> $scripts[[1]]$run_time #> [1] 0.12 #>  #> $scripts[[1]]$last_status #> $scripts[[1]]$last_status$log #> $scripts[[1]]$last_status$log[[1]] #> [1] \"\\033G3;no staging files found\" #>  #> $scripts[[1]]$last_status$log[[2]] #> [1] \"\\033g\\033G3;⠙ processing source \\033[1mepic\\033[22m (\\033[3m./data/epic/ingest.R\\033[23m)\\r\\033g\" #>  #>  #> $scripts[[1]]$last_status$success #> [1] TRUE #>  #>  #>  #>  #> $checked #> [1] \"2026-02-10 15:28:15\" #>  #> $check_results #> $check_results$`../../../pophive/pophive_demo/data/epic/standard/children.csv.gz` #> list() #>  #> $check_results$`../../../pophive/pophive_demo/data/epic/standard/county_no_time.csv.gz` #> list() #>  #> $check_results$`../../../pophive/pophive_demo/data/epic/standard/no_geo.csv.gz` #> list() #>  #> $check_results$`../../../pophive/pophive_demo/data/epic/standard/state_no_time.csv.gz` #> list() #>  #> $check_results$`../../../pophive/pophive_demo/data/epic/standard/weekly.csv.gz` #> list() #>  #>  #> $standard_state #> $standard_state$`../../../pophive/pophive_demo/data/epic/measure_info.json` #> [1] \"f8ca16b6ec149ec601da2fff8c395a14\" #>  #> $standard_state$`../../../pophive/pophive_demo/data/epic/standard/children.csv.gz` #> [1] \"538f9bfa2a7c012fcf15d9491b5ee60e\" #>  #> $standard_state$`../../../pophive/pophive_demo/data/epic/standard/county_no_time.csv.gz` #> [1] \"732265db20d823ac6b8cd7e4fa91e184\" #>  #> $standard_state$`../../../pophive/pophive_demo/data/epic/standard/no_geo.csv.gz` #> [1] \"612347598abc7970631923a099f4aa44\" #>  #> $standard_state$`../../../pophive/pophive_demo/data/epic/standard/state_no_time.csv.gz` #> [1] \"6712ffbc056f9e635545ce6c75f3e40f\" #>  #> $standard_state$`../../../pophive/pophive_demo/data/epic/standard/weekly.csv.gz` #> [1] \"29d830af361a067be287c61da0180ad5\" #>  #>  #> $vintages #> $vintages$weekly.csv.gz #> [1] \"2025-07-14\" #>  #> $vintages$state_no_time.csv.gz #> [1] \"2025-04-11\" #>  #> $vintages$county_no_time.csv.gz #> [1] \"2025-05-01\" #>  #> $vintages$no_geo.csv.gz #> [1] \"2025-06-04\" #>  #> $vintages$children.csv.gz #> [1] \"2025-05-07\" #>  #>"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_read_epic.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Epic Cosmos Data — dcf_read_epic","title":"Read Epic Cosmos Data — dcf_read_epic","text":"Read metadata data Epic Cosmos file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_read_epic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Epic Cosmos Data — dcf_read_epic","text":"","code":"dcf_read_epic(path, path_root = \".\", standard_names = NULL)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_read_epic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Epic Cosmos Data — dcf_read_epic","text":"path Path file. path_root Directory containing path, full. standard_names character vector standard dataset names names, fixed patterns search metadata values (lowercase; e.g., c(condition = \"condition name\")). take precedence existing set standard names, make sure pattern sufficiently specific target dataset.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_read_epic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read Epic Cosmos Data — dcf_read_epic","text":"list data.frame entries metadata data.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_read_epic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read Epic Cosmos Data — dcf_read_epic","text":"","code":"# write an example file path <- tempfile(fileext = \".csv\") raw_lines <- c(   \"metadata field,metadata value,\",   \",,\",   \",Measures,Value Name\",   \"Year,Measure 1,\",   \"2020,m1,1\",   \",m2,2\",   \"2021,m1,3\",   \",m2,4\" ) writeLines(raw_lines, path)  # read it in dcf_read_epic(basename(path), dirname(path)) #> $metadata #> $metadata$file #> [1] \"file85443989754c.csv\" #>  #> $metadata$md5 #> [1] \"7abcea997e7630c84a12284d5abc2b97\" #>  #> $metadata$date_processed #> [1] \"2026-02-10 15:45:44 EST\" #>  #> $metadata$standard_name #> [1] \"\" #>  #> $metadata$`metadata field` #> [1] \"metadata value\" #>  #>  #> $data #> # A tibble: 4 × 3 #>   year  measure_1 value_name #>   <chr> <chr>     <chr>      #> 1 2020  m1        1          #> 2 2020  m2        2          #> 3 2021  m1        3          #> 4 2021  m2        4          #>"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize Epic Data — dcf_standardize_epic","title":"Standardize Epic Data — dcf_standardize_epic","text":"Standardize raw Epic data table.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize Epic Data — dcf_standardize_epic","text":"","code":"dcf_standardize_epic(raw_data)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize Epic Data — dcf_standardize_epic","text":"raw_data Raw Epic data, returned dcf_read_epic.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize Epic Data — dcf_standardize_epic","text":"standardized form data.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":"standardization","dir":"Reference","previous_headings":"","what":"Standardization","title":"Standardize Epic Data — dcf_standardize_epic","text":"Collapse location columns (state county) single     geography column, region names IDs. Collapse time columns (year, month, week) single     time column, clean value formatting. Drop rows values across value columns.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_standardize_epic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize Epic Data — dcf_standardize_epic","text":"","code":"if (FALSE) { # \\dontrun{   raw_data <- dcf_read_epic(\"data/epic/raw/flu.csv.xz\")   standard_data <- dcf_process_epic_raw(raw_data) } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_status_diagram.html","id":null,"dir":"Reference","previous_headings":"","what":"Make a Status Diagram — dcf_status_diagram","title":"Make a Status Diagram — dcf_status_diagram","text":"Make Data Collection Project status diagram.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_status_diagram.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make a Status Diagram — dcf_status_diagram","text":"","code":"dcf_status_diagram(project_dir = \".\", out_file = \"status.md\")"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_status_diagram.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make a Status Diagram — dcf_status_diagram","text":"project_dir Path Data Collection Framework project built. out_file File name file write within project_dir.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_status_diagram.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make a Status Diagram — dcf_status_diagram","text":"character vector status diagram, also written project_dir/status.md file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_status_diagram.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make a Status Diagram — dcf_status_diagram","text":"","code":"if (FALSE) { # \\dontrun{   dcf_status_diagram(\"project_directory\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_to_health_region.html","id":null,"dir":"Reference","previous_headings":"","what":"Map States to Health Regions — dcf_to_health_region","title":"Map States to Health Regions — dcf_to_health_region","text":"Maps state FIPS state numeric codes Human Health Service regions.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_to_health_region.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map States to Health Regions — dcf_to_health_region","text":"","code":"dcf_to_health_region(geoids, prefix = \"Region \")"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_to_health_region.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map States to Health Regions — dcf_to_health_region","text":"geoids Character vector GEOIDs. prefix prefix add region IDs.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_to_health_region.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map States to Health Regions — dcf_to_health_region","text":"vector Health Region names length geoids.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_to_health_region.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map States to Health Regions — dcf_to_health_region","text":"","code":"dcf_to_health_region(c(\"01\", \"01001\", \"02\", \"02001\")) #> [1] \"Region 4\"  \"Region 4\"  \"Region 10\" \"Region 10\""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_update_lock.html","id":null,"dir":"Reference","previous_headings":"","what":"Update renv.lock — dcf_update_lock","title":"Update renv.lock — dcf_update_lock","text":"Updates renv.lock file dependencies found project scripts.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_update_lock.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update renv.lock — dcf_update_lock","text":"","code":"dcf_update_lock(project_dir = \".\", refresh = TRUE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_update_lock.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update renv.lock — dcf_update_lock","text":"project_dir Directory Data Collection project. refresh Logical; FALSE, update existing renv.lock file, rather recreating .","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_update_lock.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update renv.lock — dcf_update_lock","text":"Nothing; writes renv.lock file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/dcf_update_lock.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Update renv.lock — dcf_update_lock","text":"","code":"if (FALSE) { # \\dontrun{   dcf_update_lock() } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive-package.html","id":null,"dir":"Reference","previous_headings":"","what":"pophive: PopHIVE: Population Health Information and Visualization Exchange — pophive-package","title":"pophive: PopHIVE: Population Health Information and Visualization Exchange — pophive-package","text":"Collection use population health data.","code":""},{"path":[]},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"pophive: PopHIVE: Population Health Information and Visualization Exchange — pophive-package","text":"Maintainer: Micah Iserman micah.iserman@gmail.com contributors: Yale School Public Health [funder, copyright holder]","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a source project structure — pophive_add_source","title":"Adds a source project structure — pophive_add_source","text":"Establishes new data source project, used collect prepare data new source.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a source project structure — pophive_add_source","text":"","code":"pophive_add_source(name, base_dir = \"data\", open_after = interactive())"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a source project structure — pophive_add_source","text":"name Name source. base_dir Path directory containing sources. open_after Logical; FALSE, open project.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a source project structure — pophive_add_source","text":"Nothing; creates default files directories.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":"project","dir":"Reference","previous_headings":"","what":"Project","title":"Adds a source project structure — pophive_add_source","text":"Within source project, two files edits: ingest.R: primary script, automatically rerun.     store raw data resources raw/ possible,     use raw/ produce standard-format files standard/.     file sourced location processing, system paths     must relative . measure_info.json: can record information     variables included standardized data files.     See data_measure_info.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_add_source.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds a source project structure — pophive_add_source","text":"","code":"data_source_dir <- tempdir() pophive_add_source(\"source_name\", data_source_dir) list.files(paste0(data_source_dir, \"/source_name\")) #> [1] \"README.md\"         \"ingest.R\"          \"measure_info.json\" #> [4] \"project.Rproj\"     \"raw\"               \"standard\""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_check_sources.html","id":null,"dir":"Reference","previous_headings":"","what":"Check Data Sources — pophive_check_sources","title":"Check Data Sources — pophive_check_sources","text":"Check data files measure info source projects.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_check_sources.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check Data Sources — pophive_check_sources","text":"","code":"pophive_check_sources(   names = list.dirs(\"data\", recursive = FALSE, full.names = FALSE),   source_dir = \"data\",   verbose = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_check_sources.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check Data Sources — pophive_check_sources","text":"names Name names source projects. source_dir Path directory containing source projects. verbose Logical; FALSE, print status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_check_sources.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check Data Sources — pophive_check_sources","text":"list entry source, containing character vector   including issue codes: not_compressed: file appear compressed. cant_read: Failed read file . geography_missing: File contain geography column. geography_nas: file's geography column contains NAs. time_missing: File contain time column. time_nas: file's time column contains NAs. missing_info: {column_name}: file's indicated column     matching entry measure_info.json.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_check_sources.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check Data Sources — pophive_check_sources","text":"","code":"if (FALSE) { # \\dontrun{   pophive_check_sources(\"gtrends\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Data from the CDC — pophive_download_cdc","title":"Download Data from the CDC — pophive_download_cdc","text":"Download data metadata Centers Disease Control Prevention (CDC).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Data from the CDC — pophive_download_cdc","text":"","code":"pophive_download_cdc(id, out_dir = \"raw\", state = NULL, verbose = TRUE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Data from the CDC — pophive_download_cdc","text":"id ID resource (e.g., ijqb-a7ye). out_dir Directory save metadata data files. state state ID previous download; provided, download new state match. verbose Logical; FALSE, display status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Data from the CDC — pophive_download_cdc","text":"state ID downloaded files; downloads files (<id>.json <id>.csv.xz) out_dir","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":"data-cdc-gov-urls","dir":"Reference","previous_headings":"","what":"data.cdc.gov URLs","title":"Download Data from the CDC — pophive_download_cdc","text":"resource ID, 3 relevant CDC URLs: resource/<id>: redirects resource's main page,     displayed metadata data preview     (e.g., data.cdc.gov/resource/ijqb-a7ye). api/views/<id>: direct link underlying     JSON metadata (e.g., data.cdc.gov/api/views/ijqb-a7ye). api/views/<id>/rows.csv: direct link full     CSV dataset (e.g., data.cdc.gov/api/views/ijqb-a7ye/rows.csv).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_download_cdc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Data from the CDC — pophive_download_cdc","text":"","code":"if (FALSE) { # \\dontrun{   pophive_download_cdc(\"ijqb-a7ye\") } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_get_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve A Data File — pophive_get_file","title":"Retrieve A Data File — pophive_get_file","text":"Load data file source data project, list versions file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_get_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve A Data File — pophive_get_file","text":"","code":"pophive_get_file(path, date = NULL, commit_hash = NULL, versions = FALSE)"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_get_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve A Data File — pophive_get_file","text":"path Path file. date Date version load; Date, character format YYYY-MM-DD. match nearest version. commit_hash SHA signature committed version; can first 6 characters. Ignored date provided. versions Logical; TRUE, return list available version, rather ","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_get_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve A Data File — pophive_get_file","text":"versions TRUE, data.frame columns   hash, author, date, message commit.   Otherwise, path temporary file, one extracted.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_get_file.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve A Data File — pophive_get_file","text":"","code":"path <- \"../../data/wastewater/raw/flua.csv.xz\" if (file.exists(path)) {   # list versions   versions <- pophive_get_file(path, versions = TRUE)   print(versions[, c(\"date\", \"hash\")])    # extract a version to a temporary file   temp_path <- pophive_get_file(path, \"2025-05\")   basename(temp_path) } #>                             date                                     hash #> 1  Mon Jun 9 00:36:37 2025 +0000 d978116e3b12926798d8f573bc1d3e913d67a547 #> 2  Mon Jun 2 09:32:13 2025 +0000 784558d5a95e20f3950a36770f82a5a0fabebb21 #> 3 Tue May 27 13:56:02 2025 -0400 36914a3d9b47f91eba0b5d8dfddd357a700fd525 #> [1] \"flua-d97811.csv.xz\""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_load_census.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Census Population Data — pophive_load_census","title":"Download Census Population Data — pophive_load_census","text":"Download American Community Survey population data U.S. Census Bureau.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_load_census.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Census Population Data — pophive_load_census","text":"","code":"pophive_load_census(   year = 2021,   out_dir = NULL,   state_only = FALSE,   overwrite = FALSE,   verbose = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_load_census.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Census Population Data — pophive_load_census","text":"year Data year. out_dir Directory download file . state_only Logical; TRUE, load state data. still download county data. overwrite Logical; TRUE, re-download overwrite existing data. verbose Logical; FALSE, display status messages.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_load_census.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Census Population Data — pophive_load_census","text":"data.frame including GEOID region_name   states counties, along population, total within   age brackets.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_load_census.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Census Population Data — pophive_load_census","text":"","code":"if (file.exists(\"../../resources/census_population_2021.csv.xz\")) {   pophive_load_census(2021, \"../../resources\")[1:10, ] } #> ℹ reading in existing file #> ✔ reading in existing file [151ms] #>  #>    GEOID          region_name    Total <10 Years 10-14 Years 15-19 Years #> 1     01              Alabama  4997675    597446      329794      329732 #> 2     02               Alaska   735951    104061       49647       47081 #> 3     04              Arizona  7079203    852827      480043      476470 #> 4     05             Arkansas  3006309    380228      203248      203530 #> 5     06           California 39455353   4784448     2658361     2588625 #> 6     08             Colorado  5723176    671899      370266      369984 #> 7     09          Connecticut  3605330    378662      224371      245790 #> 8     10             Delaware   981892    110715       60792       61884 #> 9     11 District of Columbia   683154     78027       31449       36641 #> 10    12              Florida 21339762   2266695     1252281     1227017 #>    20-39 Years 40-64 Years 65+ Years #> 1      1283943     1612333    844427 #> 2       219748      225226     90188 #> 3      1896688     2129316   1243859 #> 4       779856      934086    505361 #> 5     11341150    12412890   5669879 #> 6      1685156     1806617    819254 #> 7       910996     1225332    620179 #> 8       245190      316936    186375 #> 9       265876      187962     83199 #> 10     5318262     6928542   4346965"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Run Data Sources — pophive_process","title":"Run Data Sources — pophive_process","text":"Optionally run ingestion script data source, collect metadata.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run Data Sources — pophive_process","text":"","code":"pophive_process(   name = NULL,   source_dir = \"data\",   ingest = TRUE,   is_auto = FALSE,   force = FALSE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run Data Sources — pophive_process","text":"name Name source project process. source_dir Path directory containing source projects. ingest Logical; FALSE, re-process standardized data without running ingestion scripts. is_auto Logical; TRUE, skip process scripts marked manual. force Logical; TRUE, ignore process frequencies (run scripts even recently run).","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Run Data Sources — pophive_process","text":"list processing results: timings: many seconds ingestion script took run. logs: captured output ingestion script. entry entry source. `datapackage.json` file also created / update source's `standard` directory.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Run Data Sources — pophive_process","text":"","code":"if (FALSE) { # \\dontrun{   # run from a directory containing a `data` directory containing the source   pophive_process(\"source_name\")    # run without executing the ingestion script   pophive_process(\"source_name\", ingest = FALSE) } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process_epic_staging.html","id":null,"dir":"Reference","previous_headings":"","what":"Process Epic Stating Files — pophive_process_epic_staging","title":"Process Epic Stating Files — pophive_process_epic_staging","text":"Process Epic stating files, lightly standardizing moving raw.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process_epic_staging.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process Epic Stating Files — pophive_process_epic_staging","text":"","code":"pophive_process_epic_staging(   staging_dir = \"raw/staging\",   out_dir = \"raw\",   verbose = TRUE,   cleanup = TRUE )"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process_epic_staging.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process Epic Stating Files — pophive_process_epic_staging","text":"staging_dir Directory containing staging files. out_dir Directory write new raw files . verbose Logical; FALSE, show status messages. cleanup Logical; FALSE, remove staging files processed.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process_epic_staging.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Process Epic Stating Files — pophive_process_epic_staging","text":"NULL staging files found.   Otherwise, list entries data metadata.   lists entries recognized standard name,   potentially combined outputs similar pophive_read_epic","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_process_epic_staging.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Process Epic Stating Files — pophive_process_epic_staging","text":"","code":"if (FALSE) { # \\dontrun{   # run from a source project   pophive_process_epic_staging() } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_read_epic.html","id":null,"dir":"Reference","previous_headings":"","what":"Read Epic Cosmos Data — pophive_read_epic","title":"Read Epic Cosmos Data — pophive_read_epic","text":"Read metadata data Epic Cosmos file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_read_epic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read Epic Cosmos Data — pophive_read_epic","text":"","code":"pophive_read_epic(path, path_root = \".\")"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_read_epic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read Epic Cosmos Data — pophive_read_epic","text":"path Path file. path_root Directory containing path, full.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_read_epic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read Epic Cosmos Data — pophive_read_epic","text":"list data.frame entries metadata data.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_read_epic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Read Epic Cosmos Data — pophive_read_epic","text":"","code":"# write an example file path <- tempfile(fileext = \".csv\") raw_lines <- c(   \"metadata field,metadata value,\",   \",,\",   \",Measures,Value Name\",   \"Year,Measure 1,\",   \"2020,m1,1\",   \",m2,2\",   \"2021,m1,3\",   \",m2,4\" ) writeLines(raw_lines, path)  # read it in pophive_read_epic(basename(path), dirname(path)) #> $metadata #> $metadata$file #> [1] \"file2d5836bb16e6.csv\" #>  #> $metadata$md5 #> [1] \"7abcea997e7630c84a12284d5abc2b97\" #>  #> $metadata$date_processed #> [1] \"2025-06-20 14:45:29 EDT\" #>  #> $metadata$standard_name #> [1] \"\" #>  #> $metadata$`metadata field` #> [1] \"metadata value\" #>  #>  #> $data #> # A tibble: 4 × 3 #>    year measure_1 value_name #>   <int> <chr>          <int> #> 1  2020 m1                 1 #> 2  2020 m2                 2 #> 3  2021 m1                 3 #> 4  2021 m2                 4 #>"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_source_process.html","id":null,"dir":"Reference","previous_headings":"","what":"Interact with a Source Process File — pophive_source_process","title":"Interact with a Source Process File — pophive_source_process","text":"Read update current source process file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_source_process.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interact with a Source Process File — pophive_source_process","text":"","code":"pophive_source_process(path = \"process.json\", updated = NULL)"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_source_process.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interact with a Source Process File — pophive_source_process","text":"path Path process JSON file. updated update version process definition. specified, write new process file, rather reading existing file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_source_process.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Interact with a Source Process File — pophive_source_process","text":"process definition source project.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_source_process.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interact with a Source Process File — pophive_source_process","text":"","code":"epic_process_file <- \"../../data/epic/process.json\" if (file.exists(epic_process_file)) {   pophive_source_process(path = epic_process_file) } #> $name #> [1] \"epic\" #>  #> $scripts #> $scripts[[1]] #> $scripts[[1]]$path #> [1] \"ingest.R\" #>  #> $scripts[[1]]$manual #> [1] TRUE #>  #> $scripts[[1]]$frequency #> [1] 0 #>  #> $scripts[[1]]$last_run #> [1] \"2025-07-01 15:07:34\" #>  #> $scripts[[1]]$run_time #> [1] 0.08 #>  #> $scripts[[1]]$last_status #> $scripts[[1]]$last_status$log #> $scripts[[1]]$last_status$log[[1]] #> [1] \"\\033G3;no staging files found\" #>  #> $scripts[[1]]$last_status$log[[2]] #> [1] \"\\033g\\033G3;⠙ processing \\033[1mepic\\033[22m (\\033[3mdata/epic/ingest.R\\033[23m)\\r\\033g\" #>  #>  #> $scripts[[1]]$last_status$success #> [1] TRUE #>  #>  #>  #>  #> $checked #> [1] \"2025-07-01 15:09:03\" #>  #> $check_results #> $check_results$`data/epic/standard/children.csv.xz` #> $check_results$`data/epic/standard/children.csv.xz`$data #> [1] \"time_missing\" #>  #>  #> $check_results$`data/epic/standard/county_no_time.csv.xz` #> $check_results$`data/epic/standard/county_no_time.csv.xz`$data #> [1] \"time_missing\" #>  #>  #> $check_results$`data/epic/standard/no_geo.csv.xz` #> $check_results$`data/epic/standard/no_geo.csv.xz`$data #> [1] \"geography_missing\" #>  #>  #> $check_results$`data/epic/standard/state_no_time.csv.xz` #> $check_results$`data/epic/standard/state_no_time.csv.xz`$data #> [1] \"time_missing\" #>  #>  #> $check_results$`data/epic/standard/weekly.csv.xz` #> list() #>  #>  #> $standard_state #> $standard_state$`data/epic/measure_info.json` #> [1] \"091570f4344efd0f8cf3dad361d86d21\" #>  #> $standard_state$`data/epic/standard/children.csv.xz` #> [1] \"15eb004a9a0b516263b6cdb74903f28b\" #>  #> $standard_state$`data/epic/standard/county_no_time.csv.xz` #> [1] \"b52c0900ece40113dc34d44d74f2a7c2\" #>  #> $standard_state$`data/epic/standard/no_geo.csv.xz` #> [1] \"43194bae68995e1de8c675cc2de90921\" #>  #> $standard_state$`data/epic/standard/state_no_time.csv.xz` #> [1] \"8a6a463098c30a20ed52b18fe857fa19\" #>  #> $standard_state$`data/epic/standard/weekly.csv.xz` #> [1] \"e770e8a3795eea9a934b91db0266b936\" #>  #>"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":null,"dir":"Reference","previous_headings":"","what":"Standardize Epic Data — pophive_standardize_epic","title":"Standardize Epic Data — pophive_standardize_epic","text":"Standardize raw Epic data table.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Standardize Epic Data — pophive_standardize_epic","text":"","code":"pophive_standardize_epic(raw_data)"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Standardize Epic Data — pophive_standardize_epic","text":"raw_data Raw Epic data, returned pophive_read_epic.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Standardize Epic Data — pophive_standardize_epic","text":"standardized form data.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":"standardization","dir":"Reference","previous_headings":"","what":"Standardization","title":"Standardize Epic Data — pophive_standardize_epic","text":"Collapse location columns (state county) single     geography column, region names IDs. Collapse time columns (year, month, week) single     time column, clean value formatting. Drop rows values across value columns.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_standardize_epic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Standardize Epic Data — pophive_standardize_epic","text":"","code":"if (FALSE) { # \\dontrun{   raw_data <- pophive_read_epic(\"data/epic/raw/flu.csv.xz\")   standard_data <- pophive_process_epic_raw(raw_data) } # }"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_to_health_region.html","id":null,"dir":"Reference","previous_headings":"","what":"Map States to Health Regions — pophive_to_health_region","title":"Map States to Health Regions — pophive_to_health_region","text":"Maps state FIPS state numeric codes Human Health Service regions.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_to_health_region.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Map States to Health Regions — pophive_to_health_region","text":"","code":"pophive_to_health_region(geoids, prefix = \"Region \")"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_to_health_region.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Map States to Health Regions — pophive_to_health_region","text":"geoids Character vector GEOIDs. prefix prefix add region IDs.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_to_health_region.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Map States to Health Regions — pophive_to_health_region","text":"vector Health Region names length geoids.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_to_health_region.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Map States to Health Regions — pophive_to_health_region","text":"","code":"pophive_to_health_region(c(\"01\", \"01001\", \"02\", \"02001\")) #> [1] \"Region 4\"  \"Region 4\"  \"Region 10\" \"Region 10\""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_update_manifest.html","id":null,"dir":"Reference","previous_headings":"","what":"Adds a source project structure — pophive_update_manifest","title":"Adds a source project structure — pophive_update_manifest","text":"Adds source project structure","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_update_manifest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Adds a source project structure — pophive_update_manifest","text":"","code":"pophive_update_manifest(path, url = NULL, description = NULL)"},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_update_manifest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Adds a source project structure — pophive_update_manifest","text":"path Path file record state . url URL file originally downloaded . description High-level description file, add metadata entry.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_update_manifest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Adds a source project structure — pophive_update_manifest","text":"List file metadata, also added manifest.json file: url URL file. description Provided description. time Time downloaded; YYYY-MM-DD HH:MM:SS TZ bytes Size file bytes. md5 MD5 hash file.","code":""},{"path":"https://DISSC-yale.github.io/dcf/reference/pophive_update_manifest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Adds a source project structure — pophive_update_manifest","text":"","code":"if (dir.exists(\"../data\")) {   # download the file   url <- paste0(     \"https://raw.githubusercontent.com/DISSC-yale/gtrends_collection/\",     \"refs/heads/main/data/term%3D%252Fg%252F11j30ybfx6/part-0.parquet\"   )   path <- tempfile(fileext = \".parquet\")   download.file(url, path, mode = \"wb\")    # add/update metadata in manifest.json   pophive_update_manifest(     path, url,     description = paste(       \"Google Trends data for the /g/11j30ybfx6\",       \"(Respiratory syncytial virus vaccine) topic.\"     )   ) }"}]
